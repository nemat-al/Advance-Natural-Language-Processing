# Advance Natural Language Processing
Tasks for Advance Natural Language Processing Course at ITMO University.

# Index
1. [Data cleaning and duplicaets detection](#data_cleaning_and_duplicaets_detection)
2. [Quora duplicates detection](#quora_duplicates_detection)
3. [Attention mechanism and Bert](#attention_mechanism_and_bert)
4. [Fine tuning and dividing documents on 10 topic categories](#fine_tuning)
5. [Topic Modeling](#topic-modeling)


### [Data cleaning and duplicaets detection](https://github.com/Nemat-Allah-Aloush/Advance-Natural-Language-Processing/blob/main/%5BNemat.Aloush.J41332c%5D.HW1.ipynb)
This file contains :
- Data Cleaning:
1. Remove non-english words
2. Remove html-tags (try to do it with regular expression, or play with beautifulsoap library)
3. Apply lemmatization / stemming
4. Remove stop-words

- Duplicates detection using LSH

### [Quora duplicates detection](https://github.com/Nemat-Allah-Aloush/Advance-Natural-Language-Processing/blob/main/%5BNemat_Aloush_J41332c%5DHW2.ipynb)
The task in this file isbuild an LSTM-based siamese homework and search for the duplicates in quora question pairs dataset.

### [Attention mechanism and Bert](https://github.com/Nemat-Allah-Aloush/Advance-Natural-Language-Processing/blob/main/%5BNemat_Aloush_J41332c%5DHW3_both.ipynb)
The task in this file is to create attention mechanism with the numpy tool. And use of pre-trained models for text processing.

### [Fine tuning](https://github.com/Nemat-Allah-Aloush/Advance-Natural-Language-Processing/blob/main/%5BNemat_Aloush_J41332c%5DHW4_tune.ipynb)
The task in this file is to divide documents on 10 topic categories using Huggingface Datasets library.

### [Topic Modeling](https://github.com/Nemat-Allah-Aloush/Advance-Natural-Language-Processing/blob/main/%5BNemat_Aloush_J41332c%5D_HW1_optional_ipynb.ipynb)
In this file I've applied topic modeling with NMF (using sklearn.decomposition.NMF) and topic modeling with LDA (using gensim implementation) in addition to applying the following two quality fuctions: coherence, and normalized PMI.
